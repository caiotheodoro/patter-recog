{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação com base de dados adquirida em aula\n",
    "\n",
    "- Carregar dataset\n",
    "- Aplicar filtros temporais\n",
    "- Realizar segmentações (tempo | frequência)\n",
    "- Criar vetores de características: VAR, RMS, ... (tempo) e FMD, FMN, ... (frequência)\n",
    "- Aplicar 1 método de seleção de característica (p.e Select Kbest)\n",
    "- Classificação (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregamento da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 1000, 4), (28, 1000, 4))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "dataGabi = np.load(\"datasets/Gabi.npy\")\n",
    "dataJesse = np.load(\"datasets/Jesse.npy\")\n",
    "\n",
    "# Entendimento dos dados\n",
    "dataGabi.shape, dataJesse.shape\n",
    "# ((28, 1000, 4), (28, 1000, 4))\n",
    "\n",
    "# Sempre tem 4 dados(4 eletrodos), os dois primeiros tem dados e os dois dps nao tem nada\n",
    "# print(dataGabi)\n",
    "# 4 -> eletrodo, canais, mas so estamos utilizando 2\n",
    "    # Usando so 2 porque estamos fazendo uma diferença de potencial\n",
    "# 28 -> classes, movimentos, comandos, amostras\n",
    "# 1000 -> quantidade de pontos, 5segundos * 200hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 28, 2, 1000)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correção do numero de eletrodos e unificação\n",
    "\n",
    "# os dois primeiros eletrodos sao funcionais\n",
    "dataGabi = dataGabi[:,:,:2]\n",
    "dataJesse = dataJesse[:,:,:2]\n",
    "\n",
    "# Entendimento dos dados\n",
    "dataGabi.shape, dataJesse.shape\n",
    "# ((28, 1000, 2), (28, 1000, 2))\n",
    "\n",
    "data = np.array([dataGabi, dataJesse])\n",
    "# data.shape\n",
    "# (2, 28, 1000, 2)\n",
    "\n",
    "# Esse transpose é so pra fazer o 1000 ir pra quarta posição\n",
    "    # Para os dados que foram capturados sempre precisam ficar na posição final\n",
    "    # O padrao de todas as funções do numpy scipy e tal é sempre em cima do axis -1 (ultima dimensao)\n",
    "    # Padronização apeans\n",
    "# Colocando os dados na dimensao final\n",
    "data = data.transpose(0,1,3,2)\n",
    "data.shape\n",
    "# (2, 28, 2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "# import numpy as np\n",
    "# from scipy import signal\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# import mne\n",
    "\n",
    "# Funções para aplicação dos filtros temporais\n",
    "def butter_bandpass(data, lowcut, highcut, fs=512, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = signal.butter(order, [low, high], btype='bandpass')\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "\n",
    "def butter_notch(data, cutoff, var=1, fs=512, order=4):\n",
    "    nyq = fs * 0.5\n",
    "    low = (cutoff - var) / nyq\n",
    "    high = (cutoff + var) / nyq\n",
    "    b, a = signal.iirfilter(order, [low, high], btype='bandstop', ftype=\"butter\")\n",
    "    return signal.filtfilt(b, a, data)\n",
    "\n",
    "FS = 200\n",
    "\n",
    "def print_graphs(data):\n",
    "    for i in range(data.shape[0]):\n",
    "        plt.plot(data[i,:])\n",
    "    plt.title('Domínio do tempo')\n",
    "    plt.show()\n",
    "\n",
    "    # for i in range(data.shape[0]):\n",
    "    #     plt.psd(data[i,:], Fs=FS)\n",
    "    # plt.title('Domínio da frequência')\n",
    "    # plt.show()\n",
    "    \n",
    "    # for i in range(data.shape[0]):\n",
    "    #     plt.specgram(data[i,:], Fs=FS)\n",
    "    # plt.title('Espectrograma')\n",
    "    # plt.show()\n",
    "\n",
    "# rcParams['figure.figsize'] = [15., 5.]\n",
    "# print_graphs(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação dos filtros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grafico do sujeito {i} depois do filtro\n",
      "Grafico do sujeito {i} depois do filtro\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 28, 2, 1000)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicação dos filtros\n",
    "rcParams['figure.figsize'] = [15., 5.]\n",
    "filtered_datas = []\n",
    "for i in range(2):\n",
    "    # print(\"Grafico do sujeito {i} antes do filtro\")\n",
    "    # print_graphs(data[i])\n",
    "    # Função para aplicar os filtros de banda e notch\n",
    "    def apply_filters(data, lowcut, highcut, notch_cutoff, notch_var=1, fs=200, order=4):\n",
    "        # Aplicar o filtro de banda\n",
    "        data = data.reshape(data.shape[1], data.shape[0], data.shape[2])\n",
    "        data_bandpass = np.apply_along_axis(lambda x: butter_bandpass(x, lowcut, highcut, fs, order), axis=-2, arr=data)\n",
    "\n",
    "        # Aplicar o filtro notch\n",
    "        data_filtered = np.apply_along_axis(lambda x: butter_notch(x, notch_cutoff, notch_var, fs, order), axis=-2, arr=data_bandpass)\n",
    "\n",
    "        return data_filtered\n",
    "\n",
    "    # Parâmetros dos filtros\n",
    "    lowcut = 0.5  # Freq. de corte inferior para o filtro de banda\n",
    "    highcut = 50.0  # Freq. de corte superior para o filtro de banda\n",
    "    notch_cutoff = 60.0  # Freq. central para o filtro notch\n",
    "    \n",
    "    # Aplicar os filtros aos dados\n",
    "    filtered_datas.append(apply_filters(data[i], lowcut, highcut, notch_cutoff))\n",
    "\n",
    "    # Verificar as dimensões dos dados filtrados\n",
    "    print(\"Grafico do sujeito {i} depois do filtro\")\n",
    "    # print_graphs(filtered_data)\n",
    "\n",
    "filtered_datas = np.array(filtered_datas)\n",
    "filtered_datas = filtered_datas.reshape(filtered_datas.shape[0], filtered_datas.shape[2], filtered_datas.shape[1], filtered_datas.shape[3])\n",
    "filtered_datas.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porque segmentar os dados em janelamento?\n",
    "- Segmenta em mais informações para levar mais contextualização para o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 2, 1000)\n"
     ]
    }
   ],
   "source": [
    "data.shape\n",
    "data = data.reshape(data.shape[0] * data.shape[1], data.shape[2], data.shape[3])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape inicial:  (56, 2, 1000)\n",
      "Formato (shape) dos dados depois da divisão de janelas\n",
      "Dominio do tempo: (56, 2, 33, 64) - (classes+ensaios, canais, janelas, linhas)\n",
      "Dominio da frequência:  (56, 2, 33, 33) - (classes+ensaios, canais, janelas, linhas)\n"
     ]
    }
   ],
   "source": [
    "# Aplicação da segmentação (dom, tempo e frequencia)\n",
    "from scipy.signal import stft\n",
    "\n",
    "step = 29 # Se mudar isso aq da problema(nao vai bater o numero de janelas)\n",
    "segment = 64\n",
    "print(\"Shape inicial: \", data.shape)\n",
    "\n",
    "n_win = int((data.shape[-1] - segment) / step) + 1\n",
    "ids = np.arange(n_win) * step\n",
    "\n",
    "# Janelas do dado no dominio do tempo\n",
    "chunks_time = np.array([data[:,:,k:(k + segment)] for k in ids]).transpose(1, 2, 0, 3)\n",
    "\n",
    "# Janelas do dado no domínio da frequência\n",
    "_, _, chunks_freq = stft(data, fs=200, nperseg=64, noverlap=32)\n",
    "chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "print('Formato (shape) dos dados depois da divisão de janelas')\n",
    "print(f'Dominio do tempo: {chunks_time.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "print(f'Dominio da frequência:  {chunks_freq.shape} - (classes+ensaios, canais, janelas, linhas)')\n",
    "\n",
    "# Quer dizer que tem 33 janelas com 64 pontos\n",
    "# 33 * 64 = 2112\n",
    "    # Faz sentido, porque temos 1000 pontos, ai como dividimos em 33 janelas de 29 passos, ele tem mais que o dobro realmente\n",
    "\n",
    "# O da frequencia saiu diferente\n",
    "    # Nao importa a quantidade de pontos na ultima dimensao, o que tem que bater é quantidade de janelas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 2*: Separar os participantes e armazenar os dados em disco para execução das próximas tarefas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 2, 33, 64)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "\n",
    "part_data = []\n",
    "\n",
    "for i in range(2):\n",
    "    part_data.append(data[i*28:(i+1)*28])\n",
    "    np.save(f\"datasets/part_data{i}.npy\", part_data[i])\n",
    "\n",
    "    n_win_time = int((part_data[i].shape[-1] - segment) / step) + 1\n",
    "    ids_time = np.arange(n_win_time) * step\n",
    "    chunks_time = np.array([part_data[i][:,:,k:(k + segment)] for k in ids_time]).transpose(1, 2, 0, 3)\n",
    "\n",
    "    _, _, chunks_freq = stft(part_data[i], fs=200, nperseg=64, noverlap=32)\n",
    "    chunks_freq = np.swapaxes(chunks_freq, 2, 3)\n",
    "\n",
    "    np.save(f\"datasets/participant_{i}_time.npy\", chunks_time)\n",
    "    np.save(f\"datasets/participant_{i}_freq.npy\", chunks_freq)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape dos dados salvos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 2, 33, 64), (28, 2, 33, 64))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_freq_1 = np.load(\"datasets/participant_0_time.npy\")\n",
    "time_freq_2 = np.load(\"datasets/participant_1_time.npy\")\n",
    "time_freq_1.shape, time_freq_2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 2, 33, 33), (28, 2, 33, 33))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_freq_1 = np.load(\"datasets/participant_0_freq.npy\")\n",
    "freq_freq_2 = np.load(\"datasets/participant_1_freq.npy\")\n",
    "\n",
    "freq_freq_1.shape, freq_freq_2.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
