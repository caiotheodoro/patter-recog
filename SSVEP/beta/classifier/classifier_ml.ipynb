{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 64, 80), (160, 64, 80), (160,), (160,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ch_ideal = [\"PZ\", \"PO3\", \"PO5\", \"PO4\", \"PO6\", \"POZ\", \"O1\", \"OZ\", \"O2\"] #canais ideais\n",
    "ch_names = [\"FP1\", \"FPZ\", \"FP2\", \"AF3\", \"AF4\", \"F7\", \"F5\", \"F3\", \"F1\", \"FZ\", \"F2\", \"F4\", \"F6\", \"F8\", \"FT7\", \"FC5\", \"FC3\", \"FC1\", \"FCZ\", \"FC2\", \"FC4\", \"FC6\", \"FT8\", \"T7\", \"C5\", \"C3\", \"C1\", \"CZ\", \"C2\", \"C4\", \"C6\", \"T8\", \"M1\", \"TP7\", \"CP5\", \"CP3\", \"CP1\", \"CPZ\", \"CP2\", \"CP4\", \"CP6\", \"TP8\", \"M2\", \"P7\", \"P5\", \"P3\", \"P1\", \"PZ\", \"P2\", \"P4\", \"P6\", \"P8\", \"PO7\", \"PO5\", \"PO3\", \"POZ\", \"PO4\", \"PO6\", \"PO8\", \"CB1\", \"O1\", \"OZ\", \"O2\", \"CB2\"]\n",
    "\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "dataset1 = np.load(\"../../datasets/beta/data1_filtered.npy\")\n",
    "dataset2 = np.load(\"../../datasets/beta/data2_filtered.npy\")\n",
    "\n",
    "labels1 = np.load(\"../../datasets/beta/labels1.npy\")\n",
    "labels2 = np.load(\"../../datasets/beta/labels2.npy\")\n",
    "# entendimento dos dados\n",
    "dataset1.shape, dataset2.shape, labels1.shape, labels2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 9, 80), (160, 9, 80))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_name_to_index = {ch_name: index for index, ch_name in enumerate(ch_names)} #dicionario de canais\n",
    "\n",
    "ideal_channel_indices = [channel_name_to_index[ch_name] for ch_name in ch_ideal] #indices dos canais ideais\n",
    "\n",
    "dataset1 = dataset1[:, ideal_channel_indices, :] #mantem apenas os canais ideais\n",
    "dataset2 = dataset2[:, ideal_channel_indices, :] \n",
    "\n",
    "dataset1.shape, dataset2.shape #verifica se os dados foram filtrados corretamente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLassificação utilizando seleção manual de características e classificador SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n",
      "acuracia: 3.12 %\n",
      "f1-score: 2.86 %\n",
      "Dataset 2\n",
      "acuracia: 31.25 %\n",
      "f1-score:  26.89 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "dataset1 = dataset1.reshape(dataset1.shape[0], dataset1.shape[1] * dataset1.shape[2]) #transforma os dados em um vetor 2D\n",
    "dataset2 = dataset2.reshape(dataset2.shape[0], dataset2.shape[1] * dataset2.shape[2]) \n",
    "\n",
    "\n",
    "X1 = StandardScaler().fit_transform(dataset1) #normaliza os dados\n",
    "y1 = LabelEncoder().fit_transform(labels1)\n",
    "\n",
    "X2 = StandardScaler().fit_transform(dataset2)\n",
    "y2 = LabelEncoder().fit_transform(labels2)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42) #separa os dados em treino e teste\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "svc =  SVC(kernel='linear', C=1, random_state=42, probability=True) #cria o classificador\n",
    "svc.fit(X_train1, y_train1) #treina o classificador\n",
    "pred1 = svc.predict(X_test1) #faz a predicao\n",
    "\n",
    "svc =  SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "svc.fit(X_train2, y_train2)\n",
    "pred2 = svc.predict(X_test2)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(\"Dataset 1\")\n",
    "print(\"acuracia: %.2f\" % (accuracy_score(y_test1, pred1)* 100),\"%\") #calcula a acuracia\n",
    "print(\"f1-score: %.2f\"% (f1_score(y_test1, pred1, average='macro')*100),\"%\") #calcula o f1-score\n",
    "\n",
    "print(\"Dataset 2\")\n",
    "print(\"acuracia: %.2f\" % (accuracy_score(y_test2, pred2)* 100),\"%\")\n",
    "print(\"f1-score:  %.2f\" % (f1_score(y_test2, pred2, average='macro')* 100),\"%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação utilizando RFE para seleção de atributos e SVM para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n",
      "acuracia: 37.50 %\n",
      "f1-score: 29.05 %\n",
      "Dataset 2\n",
      "acuracia: 50.00 %\n",
      "f1-score:  43.55 %\n",
      "(160, 400) (160, 1485)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "\n",
    "dataset1 = np.load(\"../../datasets/beta/data1_filtered.npy\")\n",
    "dataset2 = np.load(\"../../datasets/beta/data2_filtered.npy\")\n",
    "\n",
    "\n",
    "dataset1 = dataset1.reshape(dataset1.shape[0], dataset1.shape[1] * dataset1.shape[2]) #transforma os dados em um vetor 2D\n",
    "dataset2 = dataset2.reshape(dataset2.shape[0], dataset2.shape[1] * dataset2.shape[2])\n",
    "\n",
    "X1 = StandardScaler().fit_transform(dataset1) #normaliza os dados\n",
    "y1 = LabelEncoder().fit_transform(labels1)\n",
    "\n",
    "X2 = StandardScaler().fit_transform(dataset2)\n",
    "y2 = LabelEncoder().fit_transform(labels2)\n",
    "\n",
    "svc = SVC(kernel=\"linear\") #cria o classificador\n",
    "rfe = RFECV(svc, step=0.001, min_features_to_select=20, cv=3) #cria o seletor de caracteristicas\n",
    "X1 = rfe.fit_transform(X1, y1) #seleciona as caracteristicas\n",
    "X2 = rfe.fit_transform(X2, y2)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42) #separa os dados em treino e teste\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "svc =  SVC(kernel='linear', C=1, random_state=42, probability=True) #cria o classificador\n",
    "svc.fit(X_train1, y_train1) #treina o classificador\n",
    "pred1 = svc.predict(X_test1) #faz a predicao\n",
    "\n",
    "svc =  SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "svc.fit(X_train2, y_train2)\n",
    "pred2 = svc.predict(X_test2)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(\"Dataset 1\")\n",
    "print(\"acuracia: %.2f\" % (accuracy_score(y_test1, pred1)* 100),\"%\") #calcula a acuracia\n",
    "print(\"f1-score: %.2f\"% (f1_score(y_test1, pred1, average='macro')*100),\"%\") #calcula o f1-score\n",
    "\n",
    "print(\"Dataset 2\")\n",
    "print(\"acuracia: %.2f\" % (accuracy_score(y_test2, pred2)* 100),\"%\")\n",
    "print(\"f1-score:  %.2f\" % (f1_score(y_test2, pred2, average='macro')* 100),\"%\")\n",
    "print(X1.shape,X2.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação utilizando selectKbest  e SVM para classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n",
      "acuracia: 3.12 %\n",
      "f1-score: 2.02 %\n",
      "Dataset 2\n",
      "acuracia: 6.25 %\n",
      "f1-score:  3.70 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "dataset1 = np.load(\"../../datasets/beta/data1_filtered.npy\")\n",
    "dataset2 = np.load(\"../../datasets/beta/data2_filtered.npy\")\n",
    "\n",
    "\n",
    "dataset1 = dataset1.reshape(dataset1.shape[0], dataset1.shape[1] * dataset1.shape[2])\n",
    "dataset2 = dataset2.reshape(dataset2.shape[0], dataset2.shape[1] * dataset2.shape[2])\n",
    "\n",
    "X1 = StandardScaler().fit_transform(dataset1)\n",
    "y1 = LabelEncoder().fit_transform(labels1)\n",
    "\n",
    "X2 = StandardScaler().fit_transform(dataset2)\n",
    "y2 = LabelEncoder().fit_transform(labels2)\n",
    "\n",
    "# SelectKBest com F-value para seleção das features\n",
    "selector1 = SelectKBest(score_func=f_classif, k=9)\n",
    "selector2 = SelectKBest(score_func=f_classif, k=9)\n",
    "\n",
    "\n",
    "svc = SVC(kernel=\"linear\")\n",
    "X1 = selector1.fit_transform(X1, y1)\n",
    "X2 = selector2.fit_transform(X2, y2)\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "svc =  SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "svc.fit(X_train1, y_train1)\n",
    "pred1 = svc.predict(X_test1)\n",
    "\n",
    "svc =  SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "svc.fit(X_train2, y_train2)\n",
    "pred2 = svc.predict(X_test2)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "\n",
    "print(\"Dataset 1\")\n",
    "print(\"acuracia: %.2f\" % (accuracy_score(y_test1, pred1)* 100),\"%\")\n",
    "print(\"f1-score: %.2f\"% (f1_score(y_test1, pred1, average='macro')*100),\"%\")\n",
    "\n",
    "print(\"Dataset 2\")\n",
    "print(\"acuracia: %.2f\" % (accuracy_score(y_test2, pred2)* 100),\"%\")\n",
    "print(\"f1-score:  %.2f\" % (f1_score(y_test2, pred2, average='macro')* 100),\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
