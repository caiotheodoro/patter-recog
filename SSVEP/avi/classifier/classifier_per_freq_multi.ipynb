{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação por isolamento de frequência\n",
    "\n",
    "Neste notebook será realizado um exemplo de classificação, isolando todas as frequências estimuladas no conjunto de dados `AVI SSVEP Single Target`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passos para a realização da classificação:\n",
    "\n",
    "1. **Carrega** o arquivo `fif` (`mne.EpochsArray`) dos dados **filtrados**;\n",
    "2. **Determine o limiar** para isolar cada uma das frequências estimuladas. Por exemplo, a faixa de frequência para o estímulo de 6.5 Hz irá resultar em pontos (`PSD`) que irão variar de 6.3 à 6.7 Hz, caso o limiar seja de 0.2 Hz;\n",
    "3. **Obter a \"energia\"** do sinal por meio do cálculo `compute_psd` para cada uma das faixas de frequência que podem ser estimuladas. Por exemplo:\n",
    "    - Obtenha todas as frequências estimuladas. Ex: 6, 6.5, 7, 7.5, 8.2 e 9.3;\n",
    "    - Obtenha o valor mínimo e o máximo para cada frequência utilizando limiar. Ex: (5.8, 6.2), (6.3, 6.7), ...\n",
    "    - Aplique o `compute_psd` para cada tupla (min, max), por meio dos parâmetros `fmin` e `fmax` do mesmo método.\n",
    "4. Com as listas de pontos isoladas e computadas (`PSD`) para cada amostra, aplique um cálculo de característica adequada. Características manuais interessantes para este exemplo podem ser `max_value`, `average` ou `median`. No fim deste passo iremos obter um **vetor de características**;\n",
    "5. Por fim, realize a **classificação**, que será um **cálculo de voto** simples (maior valor é provavelmente o a frequência evocada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading c:\\Users\\caio-\\Documents\\facul\\patter-recog\\SSVEP\\avi\\classifier\\..\\..\\datasets\\avi\\multi\\sub1_combined-raw.fif ...\n",
      "Isotrak not found\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...   15998.05 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "100 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caio-\\AppData\\Local\\Temp\\ipykernel_3140\\343106749.py:2: RuntimeWarning: This filename (../../datasets/avi/multi/sub1_combined-raw.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  data = mne.read_epochs(\"../../datasets/avi/multi/sub1_combined-raw.fif\")\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "data = mne.read_epochs(\"../../datasets/avi/multi/sub1_combined-raw.fif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarefa 2\n",
      "\n",
      "\n",
      "[6.0, 6.5, 7.0, 7.5, 8.2, 9.3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 6, 1, 1, 7)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TAREFA 2: Início da tarefa 2\n",
    "print(\"Tarefa 2\")\n",
    "\n",
    "threshold = 0.23  # Define o valor do limite como 0.23\n",
    "data\n",
    "print(f\"\\n\") \n",
    "\n",
    "# TAREFA 3: Início da tarefa 3\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "targets = [float(item) for item in data.event_id.keys()]  # Cria uma lista de alvos a partir das chaves do dicionário 'event_id' em 'data'\n",
    "print(targets)  # imprime o tipo de 'targets'\n",
    "\n",
    "features = list()  # Inicializa uma lista vazia chamada 'features'\n",
    "for i in range(len(data)):  # Loop for que itera sobre os elementos de 'data'\n",
    "    sample = list()  # Inicializa uma lista vazia chamada 'sample'\n",
    "    for target in targets:  # Loop aninhado que itera sobre os alvos\n",
    "        fmin = target - threshold  # Calcula 'fmin' subtraindo o 'threshold' do alvo\n",
    "        fmax = target + threshold  # Calcula 'fmax' somando o 'threshold' ao alvo\n",
    "        sample.append(data[i].compute_psd(method='multitaper', fmin=fmin,\n",
    "                                          fmax=fmax, verbose=False))  # Calcula o PSD (Power Spectral Density) para o i-ésimo elemento de 'data' no intervalo [fmin, fmax] e adiciona a 'sample'\n",
    "    features.append(sample)  # Adiciona 'sample' à lista 'features'\n",
    "\n",
    "arrayFeatures = np.array(features)  # converte 'features' em um array NumPy e armazena em 'arrayFeatures'\n",
    "arrayFeatures.shape #formato dos dados(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 6)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# organizando os dados\n",
    "arrayFeatures = arrayFeatures.reshape(arrayFeatures.shape[0], arrayFeatures.shape[1], arrayFeatures.shape[-1])\n",
    "print(arrayFeatures.shape) #formato pós padronização PSD\n",
    "\n",
    "# TAREFA 4\n",
    "\n",
    "#max values do array\n",
    "maxValues = np.max(arrayFeatures, axis=-1)\n",
    "maxValues.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.00%\n"
     ]
    }
   ],
   "source": [
    "# TAREFA 5\n",
    "\n",
    "# Carrega os rótulos (labels)\n",
    "labels = np.load(\"../../datasets/avi/multi/labelsMulti_sub1.npy\")\n",
    "\n",
    "# Realiza uma verificação dos dados do rótulo carregados, exibindo os rótulos, sua forma (shape) e os targets (alvos)\n",
    "# print(labels, labels.shape, targets)\n",
    "\n",
    "# Classificação pelo maior valor\n",
    "# Encontra o índice do maior valor em maxValues e armazena em iMax\n",
    "iMax = maxValues.argmax(axis=-1)\n",
    "\n",
    "# Cria uma lista de '1' para cada índice onde o target correspondente é igual ao rótulo em iMax\n",
    "hits = [1 for i in range(len(iMax)) if targets[iMax[i]] == labels[i]]\n",
    "\n",
    "# Calcula a acurácia como a porcentagem de acertos em relação ao total de rótulos\n",
    "acc = 100 * sum(hits) / len(labels)\n",
    "\n",
    "print(f'Accuracy: {acc:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
